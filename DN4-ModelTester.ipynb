{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriented-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brief-academy",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3400, 225, 300, 3)\n",
      "Testing set shape: (600, 225, 300, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 223, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 147, 48)      27696     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 73, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 71, 32)        13856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 26, 35, 100)       3300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26, 35, 100)       10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26, 35, 100)       10100     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 91000)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 91000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 364004    \n",
      "=================================================================\n",
      "Total params: 430,848\n",
      "Trainable params: 430,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- MODEL COMPILED AND READY --------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "dn_input = np.load('/home/beto/Documents/projects/DoggoNet/DN-dataset.npz')\n",
    "\n",
    "x_train = dn_input['X_train']\n",
    "x_test = dn_input['X_test']\n",
    "y_train = dn_input['y_train']\n",
    "y_test = dn_input['y_test']\n",
    "\n",
    "print('Training set shape:', x_train.shape)\n",
    "print('Testing set shape:', x_test.shape)\n",
    "\n",
    "# convert class\n",
    "num_classes = 4\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Model initialization\n",
    "model = keras.Sequential([keras.Input(shape=(225, 300, 3))])\n",
    "\n",
    "\n",
    "# Defining building blocks\n",
    "def add_conv_lyr(num_neurons, k_size, act_func, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.Conv2D(num_neurons, kernel_size=k_size, activation=act_func))\n",
    "\n",
    "\n",
    "def add_max_pool_lyr(p_size, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.MaxPooling2D(pool_size=p_size))\n",
    "\n",
    "\n",
    "def add_dense_lyr(num_neurons, act_func, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.Dense(num_neurons, activation=act_func))\n",
    "\n",
    "\n",
    "# Adding logic to the model\n",
    "add_conv_lyr(64, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "add_conv_lyr(48, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "add_conv_lyr(32, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "\n",
    "add_dense_lyr(100, 'tanh', 3)\n",
    "\n",
    "# Ending model\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "add_dense_lyr(num_classes, 'softmax')\n",
    "model.summary()\n",
    "\n",
    "batch_size = 34 * 3\n",
    "epochs = 12\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print('\\n-------------------- MODEL COMPILED AND READY --------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-partnership",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "30/30 [==============================] - 168s 6s/step - loss: 1.3130 - accuracy: 0.4167 - val_loss: 0.9478 - val_accuracy: 0.5971\n",
      "Epoch 2/12\n",
      "30/30 [==============================] - 178s 6s/step - loss: 0.5846 - accuracy: 0.7647 - val_loss: 0.3445 - val_accuracy: 0.8735\n",
      "Epoch 3/12\n",
      "30/30 [==============================] - 181s 6s/step - loss: 0.2640 - accuracy: 0.9118 - val_loss: 0.1999 - val_accuracy: 0.9324\n",
      "Epoch 4/12\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.1661 - accuracy: 0.9431 - val_loss: 0.1830 - val_accuracy: 0.9265\n",
      "Epoch 5/12\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.1497 - accuracy: 0.9542 - val_loss: 0.2516 - val_accuracy: 0.9088\n",
      "Epoch 6/12\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.1027 - accuracy: 0.9660 - val_loss: 0.1064 - val_accuracy: 0.9618\n",
      "Epoch 7/12\n",
      "30/30 [==============================] - 187s 6s/step - loss: 0.0486 - accuracy: 0.9866 - val_loss: 0.1504 - val_accuracy: 0.9412\n",
      "Epoch 8/12\n",
      "30/30 [==============================] - 180s 6s/step - loss: 0.0557 - accuracy: 0.9797 - val_loss: 0.1614 - val_accuracy: 0.9471\n",
      "Epoch 9/12\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 0.1386 - val_accuracy: 0.9471\n",
      "Epoch 10/12\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.1166 - val_accuracy: 0.9559\n",
      "Epoch 11/12\n",
      "30/30 [==============================] - 179s 6s/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1068 - val_accuracy: 0.9706\n",
      "Epoch 12/12\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1101 - val_accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f15ec5e3898>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "rubber-beach",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-nation",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "excess-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing trained model\n",
    "def pick_image(num, dataset):\n",
    "    d = {0:'Jack',1:'Luna',2:'Volt',3:'Katy'}\n",
    "    if dataset == 'train':\n",
    "        etiqueta = dn_input['y_train'][num]\n",
    "        foto = dn_input['X_train'][num]\n",
    "    elif dataset == 'test':\n",
    "        etiqueta = dn_input['y_test'][num]\n",
    "        foto = dn_input['X_test'][num]\n",
    "    foto = np.multiply(foto, 255).astype(np.int8)\n",
    "    print('This is: {}\\nShowing image from {}ing set'.format(d[etiqueta[0]], dataset))\n",
    "    Image.fromarray(foto, 'RGB').show()\n",
    "\n",
    "def test_image(num):\n",
    "    d = {0:'Jack',1:'Luna',2:'Volt',3:'Katy'}\n",
    "    etiqueta = dn_input['y_test'][num]\n",
    "    foto = dn_input['X_test'][num]\n",
    "    foto = np.multiply(foto, 255).astype(np.int8)\n",
    "    result = model.predict(dn_input['X_test'][num].reshape(1,225,300,3)).flatten()\n",
    "    val = result.max()\n",
    "    i = np.where(np.isclose(result, val))[0][0]\n",
    "    print('Neural network predicts this is {}\\nShnp.where(np.isclose(a, value))owing image to compare'.format(d[i]))\n",
    "    Image.fromarray(foto, 'RGB').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cultural-locking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network predicts this is Volt\n",
      "Showing image to compare\n"
     ]
    }
   ],
   "source": [
    "test_image(15) # select from 0 to 599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "outside-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\n",
    "    'model_24feb21_9706_h5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format='h5',\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
