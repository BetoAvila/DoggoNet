{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assumed-distance",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3400, 225, 300, 3)\n",
      "Testing set shape: (600, 225, 300, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 223, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 147, 48)      27696     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 73, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 71, 32)        13856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 26, 35, 100)       3300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26, 35, 100)       10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26, 35, 100)       10100     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 91000)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 91000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 364004    \n",
      "=================================================================\n",
      "Total params: 430,848\n",
      "Trainable params: 430,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- MODEL COMPILED AND READY --------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "dn_input = np.load('/home/beto/Documents/projects/DoggoNet/DN-dataset.npz')\n",
    "\n",
    "x_train = dn_input['X_train']\n",
    "x_test = dn_input['X_test']\n",
    "y_train = dn_input['y_train']\n",
    "y_test = dn_input['y_test']\n",
    "\n",
    "print('Training set shape:', x_train.shape)\n",
    "print('Testing set shape:', x_test.shape)\n",
    "\n",
    "# convert class\n",
    "num_classes = 4\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Model initialization\n",
    "model = keras.Sequential([keras.Input(shape=(225, 300, 3))])\n",
    "\n",
    "\n",
    "# Defining building blocks\n",
    "def add_conv_lyr(num_neurons, k_size, act_func, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.Conv2D(num_neurons, kernel_size=k_size, activation=act_func))\n",
    "\n",
    "\n",
    "def add_max_pool_lyr(p_size, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.MaxPooling2D(pool_size=p_size))\n",
    "\n",
    "\n",
    "def add_dense_lyr(num_neurons, act_func, times=1):\n",
    "    for i in range(times):\n",
    "        model.add(layers.Dense(num_neurons, activation=act_func))\n",
    "\n",
    "\n",
    "# Adding logic to the model\n",
    "add_conv_lyr(64, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "add_conv_lyr(48, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "add_conv_lyr(32, (3, 3), 'relu')\n",
    "add_max_pool_lyr((2, 2))\n",
    "\n",
    "add_dense_lyr(100, 'tanh', 3)\n",
    "\n",
    "# Ending model\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "add_dense_lyr(num_classes, 'softmax')\n",
    "model.summary()\n",
    "\n",
    "batch_size = 34 * 3\n",
    "epochs = 18\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print('\\n-------------------- MODEL COMPILED AND READY --------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binding-camel",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "30/30 [==============================] - 195s 6s/step - loss: 1.2390 - accuracy: 0.4556 - val_loss: 0.7936 - val_accuracy: 0.6618\n",
      "Epoch 2/18\n",
      "30/30 [==============================] - 196s 7s/step - loss: 0.6223 - accuracy: 0.7507 - val_loss: 0.5596 - val_accuracy: 0.7706\n",
      "Epoch 3/18\n",
      "30/30 [==============================] - 199s 7s/step - loss: 0.3726 - accuracy: 0.8647 - val_loss: 0.3367 - val_accuracy: 0.8853\n",
      "Epoch 4/18\n",
      "30/30 [==============================] - 197s 7s/step - loss: 0.2685 - accuracy: 0.9082 - val_loss: 0.2687 - val_accuracy: 0.9088\n",
      "Epoch 5/18\n",
      "30/30 [==============================] - 192s 6s/step - loss: 0.1540 - accuracy: 0.9497 - val_loss: 0.1867 - val_accuracy: 0.9235\n",
      "Epoch 6/18\n",
      "30/30 [==============================] - 193s 6s/step - loss: 0.0944 - accuracy: 0.9699 - val_loss: 0.1445 - val_accuracy: 0.9471\n",
      "Epoch 7/18\n",
      "30/30 [==============================] - 192s 6s/step - loss: 0.0622 - accuracy: 0.9817 - val_loss: 0.1603 - val_accuracy: 0.9471\n",
      "Epoch 8/18\n",
      "30/30 [==============================] - 198s 7s/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.1120 - val_accuracy: 0.9618\n",
      "Epoch 9/18\n",
      "30/30 [==============================] - 195s 7s/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.1219 - val_accuracy: 0.9647\n",
      "Epoch 10/18\n",
      "30/30 [==============================] - 194s 6s/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.1125 - val_accuracy: 0.9706\n",
      "Epoch 11/18\n",
      "30/30 [==============================] - 197s 7s/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1165 - val_accuracy: 0.9588\n",
      "Epoch 12/18\n",
      "30/30 [==============================] - 194s 6s/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.1131 - val_accuracy: 0.9647\n",
      "Epoch 13/18\n",
      "30/30 [==============================] - 195s 7s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.1549 - val_accuracy: 0.9559\n",
      "Epoch 14/18\n",
      "30/30 [==============================] - 194s 6s/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.1031 - val_accuracy: 0.9588\n",
      "Epoch 15/18\n",
      "30/30 [==============================] - 195s 6s/step - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.1293 - val_accuracy: 0.9500\n",
      "Epoch 16/18\n",
      "30/30 [==============================] - 194s 6s/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.1993 - val_accuracy: 0.9500\n",
      "Epoch 17/18\n",
      "30/30 [==============================] - 196s 7s/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.1310 - val_accuracy: 0.9618\n",
      "Epoch 18/18\n",
      "30/30 [==============================] - 196s 7s/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1497 - val_accuracy: 0.9706\n",
      "60.63184737761815 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "print((time.time() - start_time) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepting-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32, numpy=\n",
       " array([[[[-8.63986090e-02,  2.30772123e-02, -7.20379651e-02, ...,\n",
       "            4.23043547e-03,  6.58809543e-02,  8.65409151e-02],\n",
       "          [-1.15540558e-02,  3.34711298e-02,  5.04642017e-02, ...,\n",
       "           -8.76927655e-03, -6.34524450e-02,  1.72126926e-02],\n",
       "          [-2.30328180e-02, -4.20531817e-02, -9.47034545e-03, ...,\n",
       "            5.35874106e-02,  8.79936218e-02, -7.04954416e-02]],\n",
       " \n",
       "         [[ 6.12664595e-03, -5.12070246e-02, -6.05488382e-03, ...,\n",
       "            4.86442558e-02,  3.47115844e-02,  5.20541072e-02],\n",
       "          [ 2.41833609e-02,  8.87548830e-03, -6.84922375e-03, ...,\n",
       "           -4.13448643e-03,  1.51918624e-02,  2.22651605e-02],\n",
       "          [-2.42343135e-02, -7.12586418e-02,  8.05987492e-02, ...,\n",
       "            7.90896825e-03, -5.59948832e-02,  2.94862986e-02]],\n",
       " \n",
       "         [[ 9.47601050e-02, -1.42582646e-02, -8.39072466e-02, ...,\n",
       "            6.29676580e-02, -4.93591540e-02,  5.34114428e-02],\n",
       "          [-9.77444872e-02,  4.67154011e-02, -5.41830100e-02, ...,\n",
       "           -2.07483675e-03, -1.06106117e-01,  1.31859621e-02],\n",
       "          [-1.00169420e-01, -5.30202165e-02, -9.24600065e-02, ...,\n",
       "           -1.73460525e-02, -7.34136254e-02, -7.78729171e-02]]],\n",
       " \n",
       " \n",
       "        [[[-5.69218732e-02, -2.35613137e-02,  2.21537873e-02, ...,\n",
       "           -5.69108466e-04,  6.29299134e-02,  9.45509598e-02],\n",
       "          [ 1.44050410e-02, -5.39572984e-02,  8.13224316e-02, ...,\n",
       "            7.75865279e-03,  3.43001559e-02,  6.96531385e-02],\n",
       "          [-3.80567089e-02, -7.21482486e-02,  9.26011130e-02, ...,\n",
       "           -1.60925724e-02,  5.28575107e-02,  7.84536973e-02]],\n",
       " \n",
       "         [[ 7.83057511e-02, -7.41214976e-02, -2.51628254e-02, ...,\n",
       "           -5.84288724e-02,  9.78320390e-02, -2.88290698e-02],\n",
       "          [-3.15552838e-02,  2.68176757e-03,  9.43255350e-02, ...,\n",
       "            3.76498178e-02,  1.88944452e-02,  4.54032719e-02],\n",
       "          [-2.60010771e-02,  1.12560995e-01, -4.24815565e-02, ...,\n",
       "           -1.03944130e-01, -4.54403125e-02, -6.87352894e-03]],\n",
       " \n",
       "         [[ 7.24377185e-02,  1.19353019e-01,  1.70332137e-02, ...,\n",
       "           -1.26138255e-02, -4.83471155e-02,  3.26174013e-02],\n",
       "          [ 4.64093760e-02, -3.14183086e-02,  4.66548949e-02, ...,\n",
       "            1.39913959e-02,  7.27960467e-02, -6.49623796e-02],\n",
       "          [ 6.82754442e-02, -3.16386744e-02,  7.32784346e-02, ...,\n",
       "           -2.06867475e-02,  1.38137746e-03,  8.17662105e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.28728524e-02,  8.63049999e-02,  8.02977756e-03, ...,\n",
       "            6.43738210e-02,  9.05463845e-02, -1.22147321e-03],\n",
       "          [-1.03665546e-01,  1.82150956e-02, -2.34969426e-02, ...,\n",
       "           -6.38000816e-02, -4.24468964e-02, -8.39067101e-02],\n",
       "          [ 7.61294886e-02, -5.66097982e-02,  8.48929361e-02, ...,\n",
       "            3.49351065e-03, -6.75123483e-02,  7.16700330e-02]],\n",
       " \n",
       "         [[ 6.55281171e-02, -6.90876245e-02,  2.10775565e-02, ...,\n",
       "            3.83188538e-02,  9.24802870e-02, -3.98101769e-02],\n",
       "          [-9.55413282e-02,  3.56502384e-02,  9.93289426e-03, ...,\n",
       "           -3.99099961e-02, -8.75271577e-03,  6.20496534e-02],\n",
       "          [ 7.48182163e-02,  1.14231408e-02,  4.33294140e-02, ...,\n",
       "           -3.79337519e-02, -8.25857278e-03, -8.97443891e-02]],\n",
       " \n",
       "         [[ 9.70253795e-02, -3.61039862e-02, -5.97074144e-02, ...,\n",
       "            5.85889369e-02, -8.84870663e-02, -9.94618163e-02],\n",
       "          [ 7.22577721e-02,  1.12018855e-02,  6.49820268e-03, ...,\n",
       "           -5.23115210e-02, -1.96723528e-02,  1.73387378e-02],\n",
       "          [ 5.45378663e-02,  1.32312048e-02, -9.14000794e-02, ...,\n",
       "            4.95299958e-02,  5.61894029e-02, -7.58369715e-05]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.0141533 ,  0.05572765, -0.00751442, -0.0001778 , -0.00160603,\n",
       "        -0.0003623 , -0.00799257, -0.01244754,  0.00275024, -0.01241494,\n",
       "        -0.01659725, -0.00134893, -0.01735386, -0.02076102,  0.00191176,\n",
       "         0.00563416,  0.0015757 , -0.01300784,  0.00208757, -0.01787654,\n",
       "         0.00298429, -0.00379588, -0.02061108, -0.00187521, -0.00336156,\n",
       "        -0.01183276, -0.01296982, -0.01991435, -0.0079793 , -0.02709135,\n",
       "        -0.01225146,  0.00473522,  0.01718099, -0.00901766, -0.00465426,\n",
       "        -0.02076063, -0.00813393, -0.00667959, -0.026515  ,  0.01070045,\n",
       "         0.00359965, -0.0072986 , -0.00914102,  0.01812835, -0.00846002,\n",
       "        -0.01426621, -0.00704207, -0.00385792, -0.00902289, -0.01368724,\n",
       "        -0.01471598,  0.00406786, -0.00609884,  0.00171488, -0.00400622,\n",
       "         0.01213608, -0.00613482, -0.01569031, -0.01378256, -0.01525504,\n",
       "         0.01693726,  0.0088211 , -0.01279216, -0.01498417], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "sensitive-ferry",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name(Nadam):\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flying-heater",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aware-cradle",
   "metadata": {},
   "source": [
    "# Testing trained model\n",
    "def pick_image(num, dataset):\n",
    "    d = {0:'Jack',1:'Luna',2:'Volt',3:'Katy'}\n",
    "    if dataset == 'train':\n",
    "        etiqueta = dn_input['y_train'][num]\n",
    "        foto = dn_input['X_train'][num]\n",
    "    elif dataset == 'test':\n",
    "        etiqueta = dn_input['y_test'][num]\n",
    "        foto = dn_input['X_test'][num]\n",
    "    foto = np.multiply(foto, 255).astype(np.int8)\n",
    "    print('This is: {}\\nShowing image from {}ing set'.format(d[etiqueta[0]], dataset))\n",
    "    Image.fromarray(foto, 'RGB').show()\n",
    "\n",
    "def test_image(num):\n",
    "    d = {0:'Jack',1:'Luna',2:'Volt',3:'Katy'}\n",
    "    etiqueta = dn_input['y_test'][num]\n",
    "    foto = dn_input['X_test'][num]\n",
    "    foto = np.multiply(foto, 255).astype(np.int8)\n",
    "    result = model.predict(dn_input['X_test'][num].reshape(1,225,300,3)).flatten()\n",
    "    val = result.max()\n",
    "    i = np.where(np.isclose(result, val))[0][0]\n",
    "    print('Neural network predicts this is {}\\nShnp.where(np.isclose(a, value))owing image to compare'.format(d[i]))\n",
    "    Image.fromarray(foto, 'RGB').show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "developed-lightweight",
   "metadata": {},
   "source": [
    "test_image(15) # select from 0 to 599"
   ]
  },
  {
   "cell_type": "raw",
   "id": "specified-section",
   "metadata": {},
   "source": [
    "model.save(\n",
    "    'model_24feb21_9706_h5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format='h5',\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-tracy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
